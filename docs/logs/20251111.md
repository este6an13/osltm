## November 11th, 2025

### Summary

I added a new script, `src/scripts/analysis/check_overdispersion.py`, to calculate **overdispersion** directly from the **original dataset** instead of using the aggregated data in the database.
While testing it, I realized there were some flaws in how I was calculating overdispersion in `src/scripts/simulate/v1/simulate_flows_average.py` and in the notebook `src/scripts/notebooks/20251109/simulating_flows_from_aggregates.ipynb`.

Basically, I was calculating the **variance across days** from the **mean estimates**, but that’s not the right approach.
Instead, I should compute the **variance per interval** using the **raw data**, and then — if I want an average measure across days — average those variances.
This way, I can tell whether a given time window for a given station and date type tends to show overdispersion on average.

To support this, I’ll create a **new version of the data model (V2)** that stores the **variance per time window**, so later I can check for overdispersion at runtime.

### Method and Implementation

1. **Fixing the overdispersion calculation**

   * The old version calculated variance across days using daily means.
   * The new version computes variance within each interval from the raw data.
   * Then, if needed, I can average those variances across days for each station and date type.

2. **Updating the data model**

   * I’ll create a **V2 schema** that includes:

     * The 15-minute **count**.
     * The corresponding **variance** for that same interval.
   * This will make it easier to test for overdispersion and later build intensity models that adapt at runtime.

3. **About count aggregation**

   * I noticed that averaging 5-minute counts to get 15-minute estimates isn’t actually necessary.
   * I can just store the **15-minute raw count**, and if I need a 5-minute estimate, I can derive it assuming a **homogeneous Poisson process**:
     $$
     \hat{\lambda}^{(5)} = \frac{N_t^{(15)}}{15} \cdot 5=\frac{N_t^{(15)}}{3}
     $$
   * So now, to get a 15-minute total, I no longer need to multiply up from smaller windows — I’ll just store the 15-minute totals directly.

4. **Other notes**

   * Storing **integers** might help save some space, though I’ll also be adding variance columns.
   * I’m not including **interarrival or waiting times** yet, but at some point it might be useful to add them — maybe as averages per time window.

### Decisions

1. Create the **V2 data model** including both count and variance per time window.
2. Add a new populate script for check-ins and check-outs using this updated model.
3. Drop the 5-minute averaging step and store 15-minute raw counts instead.
4. Use variance from raw data (not aggregated means) to check for **overdispersion**.
5. Next steps: verify overdispersion patterns and move toward **intensity function estimation**.

### Assumptions to Validate

1. Overdispersion should be measured from **raw data**, not daily means.
2. Averaging variances across days gives a good estimate of how consistent the overdispersion is.
3. The **homogeneous Poisson process** assumption holds reasonably well inside each 15-minute window.
4. Adding variance to the data model won’t create significant storage issues.
5. Interarrival or waiting times might add value later, but aren’t necessary for this stage.
